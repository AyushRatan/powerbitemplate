{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b28d6a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "241c36b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Report_Name</th>\n",
       "      <th>Page_Name</th>\n",
       "      <th>Visual_Title</th>\n",
       "      <th>Visual_Type</th>\n",
       "      <th>Columns</th>\n",
       "      <th>Responses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POC_Regional_Sales</td>\n",
       "      <td>Sales Overview</td>\n",
       "      <td>Revenue Open by Sales Stage</td>\n",
       "      <td>funnel</td>\n",
       "      <td>Sales Stage, Revenue Open</td>\n",
       "      <td>The Revenue Open by Sales Stage visual in Powe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POC_Regional_Sales</td>\n",
       "      <td>Sales Overview</td>\n",
       "      <td>Forecast by Location</td>\n",
       "      <td>shapeMap</td>\n",
       "      <td>State or Province, State or Province.1, Rev Go...</td>\n",
       "      <td>The Power BI visual Forecast by Location is a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POC_Regional_Sales</td>\n",
       "      <td>Sales Overview</td>\n",
       "      <td>Revenue Won and Revenue In Pipeline by Product...</td>\n",
       "      <td>barChart</td>\n",
       "      <td>Product Category, Product, Revenue Won, Revenu...</td>\n",
       "      <td>The Power BI visual \"Revenue Won and Revenue I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Report_Name       Page_Name  \\\n",
       "0  POC_Regional_Sales  Sales Overview   \n",
       "1  POC_Regional_Sales  Sales Overview   \n",
       "2  POC_Regional_Sales  Sales Overview   \n",
       "\n",
       "                                        Visual_Title Visual_Type  \\\n",
       "0                        Revenue Open by Sales Stage      funnel   \n",
       "1                               Forecast by Location    shapeMap   \n",
       "2  Revenue Won and Revenue In Pipeline by Product...    barChart   \n",
       "\n",
       "                                             Columns  \\\n",
       "0                          Sales Stage, Revenue Open   \n",
       "1  State or Province, State or Province.1, Rev Go...   \n",
       "2  Product Category, Product, Revenue Won, Revenu...   \n",
       "\n",
       "                                           Responses  \n",
       "0  The Revenue Open by Sales Stage visual in Powe...  \n",
       "1  The Power BI visual Forecast by Location is a ...  \n",
       "2  The Power BI visual \"Revenue Won and Revenue I...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_name = \"MasterData\"\n",
    "file_path_4 = os.path.join(folder_name, f\"Merged_MasterData.xlsx\")\n",
    "main_df = pd.read_excel(file_path_4)\n",
    "main_df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d5d72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ChatGPT\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to encode text using BERT\n",
    "def encode_text(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt')\n",
    "    outputs = model(**inputs)\n",
    "    return outputs.pooler_output.detach().numpy()\n",
    "\n",
    "# Function to compute cosine similarity\n",
    "def compute_similarity(query_embedding, description_embeddings):\n",
    "    similarities = cosine_similarity(query_embedding, description_embeddings)\n",
    "    return similarities\n",
    "\n",
    "# Function to get top N matching records\n",
    "def get_top_matches(query, descriptions, top_n=3):\n",
    "    query_embedding = encode_text(query)\n",
    "    description_embeddings = [encode_text(desc) for desc in descriptions]\n",
    "\n",
    "    similarities = compute_similarity(query_embedding, description_embeddings)\n",
    "    top_indices = similarities.argsort(axis=1)[0][-top_n:][::-1]\n",
    "\n",
    "    top_matches = [(descriptions[i], similarities[0, i]) for i in top_indices]\n",
    "    return top_matches\n",
    "\n",
    "# Sample metadata sheet\n",
    "data = {\n",
    "    'Report_Name': ['Report1', 'Report2', 'Report3'],\n",
    "    'Page_Name': ['Page1', 'Page2', 'Page3'],\n",
    "    'Visual_Title': ['Title1', 'Title2', 'Title3'],\n",
    "    'Visual_Type': ['Type1', 'Type2', 'Type3'],\n",
    "    'Columns': ['Col1', 'Col2', 'Col3'],\n",
    "    'Description': ['Description1 for Report1', 'Description2 for Report2', 'Description3 for Report3']\n",
    "}\n",
    "\n",
    "metadata_df = pd.DataFrame(data)\n",
    "\n",
    "# User query\n",
    "user_query = \"I'm looking for a report with sales data.\"\n",
    "\n",
    "# Perform similarity search\n",
    "top_matches = get_top_matches(user_query, metadata_df['Description'])\n",
    "\n",
    "# Print the top matching records\n",
    "for match, similarity in top_matches:\n",
    "    print(f\"Description: {match}\\nSimilarity: {similarity}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b259117b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bard\n",
    "import pandas as pd\n",
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv(\"meta_data.csv\")\n",
    "\n",
    "# Load the LLM model and tokenizer\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def search(query):\n",
    "    # Encode the query and descriptions\n",
    "    query_encoded = tokenizer(query, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "    descriptions_encoded = tokenizer(data[\"Description\"], truncation=True, padding=True, return_tensors=\"pt\")\n",
    "\n",
    "    # Perform question answering on the descriptions\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**query_encoded, **descriptions_encoded)\n",
    "        start_logits = outputs.start_logits\n",
    "        end_logits = outputs.end_logits\n",
    "\n",
    "    # Identify the top 3 matching records\n",
    "    top_3_indices = start_logits.topk(3, dim=1)[1]\n",
    "\n",
    "    # Extract the top 3 matching descriptions\n",
    "    top_3_descriptions = [data[\"Description\"].iloc[index] for index in top_3_indices.tolist()]\n",
    "\n",
    "    # Return the top 3 matching records\n",
    "    return top_3_descriptions\n",
    "\n",
    "# Example usage\n",
    "query = \"What are the most important visuals in the Power BI report?\"\n",
    "top_3_descriptions = search(query)\n",
    "\n",
    "print(top_3_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1a4904",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bard\n",
    "import openai\n",
    "import pandas as pd\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = \"YOUR_OPENAI_API_KEY\"\n",
    "\n",
    "# Load the metadata sheet into a Pandas DataFrame\n",
    "data = pd.read_csv(\"metadata_sheet.csv\")\n",
    "\n",
    "# Function to perform similarity search using OpenAI embeddings\n",
    "def similarity_search(query, data):\n",
    "    # Convert the query and Description columns to embeddings\n",
    "    query_embedding = openai.Embedding.create(input=[query])[\"data\"][0][\"embedding\"]\n",
    "    description_embeddings = [\n",
    "        openai.Embedding.create(input=[description])[\"data\"][0][\"embedding\"]\n",
    "        for description in data[\"Description\"]\n",
    "    ]\n",
    "\n",
    "    # Calculate cosine similarities between the query embedding and each description embedding\n",
    "    similarities = [\n",
    "        np.dot(query_embedding, description_embedding)\n",
    "        for description_embedding in description_embeddings\n",
    "    ]\n",
    "\n",
    "    # Sort the similarities and return the top 3 matching records\n",
    "    top_3_matches = sorted(zip(similarities, data), key=lambda x: x[0], reverse=True)[:3]\n",
    "    return top_3_matches\n",
    "\n",
    "# Example usage\n",
    "query = \"What are the most popular visuals used in Power BI reports?\"\n",
    "top_3_matches = similarity_search(query, data)\n",
    "\n",
    "# Print the top 3 matching records\n",
    "for match in top_3_matches:\n",
    "    print(match[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eae10a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ChatGPT\n",
    "import openai\n",
    "\n",
    "# Set your OpenAI API key here\n",
    "openai.api_key = 'YOUR_OPENAI_API_KEY'\n",
    "\n",
    "def get_top_matching_records(query, records, num_results=3):\n",
    "    # Construct prompt for GPT-3\n",
    "    prompt = f\"Query: {query}\\nRecords:\\n\" + \"\\n\".join(records)\n",
    "\n",
    "    # Call GPT-3 to get the response\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"davinci-codex\",  # Use the Codex engine for code-related queries\n",
    "        prompt=prompt,\n",
    "        max_tokens=150,  # Adjust as needed\n",
    "        n=3,  # Number of completions to generate\n",
    "    )\n",
    "\n",
    "    # Extract and return the top n choices from GPT-3 response\n",
    "    choices = [choice[\"text\"] for choice in response['choices'][:num_results]]\n",
    "    return choices\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Sample data\n",
    "    records = [\n",
    "        \"Report1\tPage1\tChart1\tBar Chart\tColumn1, Column2\tSales data\",\n",
    "        \"Report2\tPage2\tTable1\tTable\tColumn3, Column4\tExpense data\",\n",
    "        # ... (add your other records)\n",
    "    ]\n",
    "\n",
    "    # User query\n",
    "    user_query = \"Give me information about sales.\"\n",
    "\n",
    "    # Get top matching records\n",
    "    matching_records = get_top_matching_records(user_query, records)\n",
    "\n",
    "    # Display the results\n",
    "    print(\"Top matching records:\")\n",
    "    for i, record in enumerate(matching_records, 1):\n",
    "        print(f\"{i}. {record}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aced8cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chatGPT\n",
    "import openai\n",
    "import faiss\n",
    "import pandas as pd\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = 'your_openai_api_key'\n",
    "\n",
    "# Load your metadata sheet into a Pandas DataFrame\n",
    "# Replace 'your_metadata.csv' with the actual path to your metadata CSV file\n",
    "metadata_path = 'your_metadata.csv'\n",
    "metadata_df = pd.read_csv(metadata_path)\n",
    "\n",
    "# Specify the columns for processing\n",
    "query_column = 'Description'\n",
    "output_columns = ['Report_Name', 'Page_Name', 'Visual_Title', 'Visual_Type', 'Columns', 'Description']\n",
    "\n",
    "# Function to encode text using OpenAI GPT-3 embeddings\n",
    "def encode_text(text):\n",
    "    response = openai.Completion.create(\n",
    "        model=\"text-davinci-003\",\n",
    "        prompt=text,\n",
    "        temperature=0,\n",
    "        max_tokens=512,\n",
    "        n=1,\n",
    "    )\n",
    "    return response['choices'][0]['text'].strip()\n",
    "\n",
    "# Encode each description in the metadata DataFrame\n",
    "encoded_descriptions = [encode_text(description) for description in metadata_df[query_column]]\n",
    "\n",
    "# Convert the encoded descriptions to a numpy array\n",
    "encoded_descriptions_array = [list(map(float, encoded.split())) for encoded in encoded_descriptions]\n",
    "encoded_descriptions_np = np.array(encoded_descriptions_array).astype('float32')\n",
    "\n",
    "# Build the FAISS index\n",
    "index = faiss.IndexFlatL2(768)  # Assuming GPT-3 embeddings are of size 768\n",
    "index.add(encoded_descriptions_np)\n",
    "\n",
    "# Function to perform similarity search and return the top-k matches\n",
    "def get_top_k_matches(query, k=3):\n",
    "    encoded_query = encode_text(query)\n",
    "    encoded_query_np = np.array([list(map(float, encoded_query.split()))]).astype('float32')\n",
    "\n",
    "    # Search for the top-k similar descriptions\n",
    "    _, indices = index.search(encoded_query_np, k)\n",
    "\n",
    "    # Return the top-k matching records from the metadata DataFrame\n",
    "    top_k_matches = metadata_df.iloc[indices[0]][output_columns]\n",
    "    return top_k_matches\n",
    "\n",
    "# Example usage\n",
    "user_query = \"Provide insights on sales trends\"\n",
    "top_matches = get_top_k_matches(user_query)\n",
    "print(top_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9cbd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bard\n",
    "import faiss\n",
    "import openai\n",
    "import pandas as pd\n",
    "\n",
    "# Replace with your OpenAI API key\n",
    "openai.api_key = \"YOUR_OPENAI_API_KEY\"\n",
    "\n",
    "# Load the metadata sheet\n",
    "metadata = pd.read_csv(\"metadata.csv\")\n",
    "\n",
    "# Create an index from the Description column\n",
    "index = faiss.IndexFlatL2(128)\n",
    "descriptions = metadata[\"Description\"].tolist()\n",
    "embeddings = openai.Embedding.create(descriptions)\n",
    "index.add(embeddings)\n",
    "\n",
    "# Search for similar descriptions\n",
    "def search(query):\n",
    "    query_embedding = openai.Embedding.create(query)\n",
    "    D, I = index.search(query_embedding, 3)\n",
    "\n",
    "    # Extract matching records from metadata\n",
    "    matching_records = []\n",
    "    for i in I:\n",
    "        matching_record = metadata.iloc[i]\n",
    "        matching_records.append(matching_record)\n",
    "\n",
    "    return matching_records\n",
    "\n",
    "# Example usage\n",
    "query = \"What are the top 3 sales by region?\"\n",
    "matching_records = search(query)\n",
    "for record in matching_records:\n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa34921d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bard\n",
    "import openai\n",
    "import faiss\n",
    "import pandas as pd\n",
    "\n",
    "# Set OpenAI API key\n",
    "openai.api_key = \"YOUR_OPENAI_API_KEY\"\n",
    "\n",
    "# Load the metadata sheet\n",
    "metadata = pd.read_csv(\"metadata.csv\")\n",
    "\n",
    "# Create a function to embed text using OpenAI\n",
    "def embed_text(text):\n",
    "    response = openai.Completion.create(\n",
    "        prompt=\"Embed the following text: \" + text,\n",
    "        engine=\"davinci\",\n",
    "        max_tokens=1024,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "    embedding = response[\"choices\"][0][\"embeddings\"][0]\n",
    "    return embedding\n",
    "\n",
    "# Embed the description column and query\n",
    "description_embeddings = []\n",
    "for description in metadata[\"Description\"]:\n",
    "    description_embedding = embed_text(description)\n",
    "    description_embeddings.append(description_embedding)\n",
    "\n",
    "query_embedding = embed_text(query)\n",
    "\n",
    "# Initialize FAISS index\n",
    "index = faiss.IndexFlatL2(1024)\n",
    "index.add_with_ids(np.array(description_embeddings), np.arange(len(metadata)))\n",
    "\n",
    "# Search for similar descriptions\n",
    "D, I = index.search(np.array([query_embedding]), 10)\n",
    "\n",
    "# Filter results based on similarity threshold\n",
    "filtered_results = []\n",
    "for i, d in zip(I[0], D[0]):\n",
    "    if d > 0.6:\n",
    "        filtered_results.append((i, d))\n",
    "\n",
    "# Select the top 3 matching records\n",
    "top_3_records = []\n",
    "for i, d in filtered_results[:3]:\n",
    "    record = {\n",
    "        \"Report_Name\": metadata[\"Report_Name\"].iloc[i],\n",
    "        \"Page_Name\": metadata[\"Page_Name\"].iloc[i],\n",
    "        \"Visual_Title\": metadata[\"Visual_Title\"].iloc[i],\n",
    "        \"Visual_Type\": metadata[\"Visual_Type\"].iloc[i],\n",
    "        \"Columns\": metadata[\"Columns\"].iloc[i],\n",
    "        \"Description\": metadata[\"Description\"].iloc[i],\n",
    "        \"Similarity\": d,\n",
    "    }\n",
    "    top_3_records.append(record)\n",
    "\n",
    "# Print the top 3 matching records\n",
    "print(top_3_records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac6f200",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chatGPT\n",
    "import openai\n",
    "import faiss\n",
    "import pandas as pd\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = 'YOUR_OPENAI_API_KEY'\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'Report_Name': ['Report1', 'Report2', 'Report3'],\n",
    "    'Page_Name': ['Page1', 'Page2', 'Page3'],\n",
    "    'Visual_Title': ['Title1', 'Title2', 'Title3'],\n",
    "    'Visual_Type': ['Type1', 'Type2', 'Type3'],\n",
    "    'Columns': ['Col1', 'Col2', 'Col3'],\n",
    "    'Description': ['Description1', 'Description2', 'Description3']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# User query\n",
    "user_query = \"Tell me about the data in the report\"\n",
    "\n",
    "# Step 1: Use OpenAI embeddings for description column and query\n",
    "embeddings = openai.Embed.create(\n",
    "    engine=\"davinci-codex\",\n",
    "    prompt=[f\"Description: {desc}\\nQuery: {user_query}\" for desc in df['Description']],\n",
    "    temperature=0,\n",
    "    max_tokens=50\n",
    ")\n",
    "\n",
    "description_embeddings = [response['choices'][0]['text'] for response in embeddings['choices']]\n",
    "\n",
    "# Step 2: Use FAISS to search for similarity\n",
    "description_matrix = [list(map(float, embedding.split())) for embedding in description_embeddings]\n",
    "query_embedding = list(map(float, embeddings['choices'][0]['text'].split()))\n",
    "\n",
    "description_matrix = faiss.normalize_L2(description_matrix)\n",
    "query_embedding = faiss.normalize_L2(query_embedding)\n",
    "\n",
    "d = len(description_matrix[0])  # Dimension of the vectors\n",
    "\n",
    "index = faiss.IndexFlatIP(d)\n",
    "index.add(description_matrix)\n",
    "\n",
    "k = 3  # Top 3 results\n",
    "\n",
    "# Search for similar vectors\n",
    "distances, indices = index.search(query_embedding.reshape(1, -1), k)\n",
    "\n",
    "# Step 3: Keep a threshold of 60%\n",
    "threshold = 0.6\n",
    "matching_records = df.iloc[indices[0][distances[0] > threshold]]\n",
    "\n",
    "# Step 4: Further semantic matching using OpenAI model\n",
    "semantic_matchings = []\n",
    "for _, record in matching_records.iterrows():\n",
    "    semantic_match = openai.Completion.create(\n",
    "        engine=\"davinci-codex\",\n",
    "        prompt=f\"Match the following records:\\n1. Description: {user_query}\\n2. Description: {record['Description']}\",\n",
    "        temperature=0,\n",
    "        max_tokens=50\n",
    "    )\n",
    "    semantic_matchings.append((record, semantic_match['choices'][0]['text']))\n",
    "\n",
    "# Print the results\n",
    "print(\"Matching Records:\")\n",
    "for record, semantic_match in semantic_matchings:\n",
    "    print(f\"Report: {record['Report_Name']}, Description: {record['Description']}\")\n",
    "    print(f\"Semantic Match: {semantic_match}\")\n",
    "    print(\"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
