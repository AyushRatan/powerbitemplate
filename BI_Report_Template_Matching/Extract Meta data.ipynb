{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a99002d9",
   "metadata": {},
   "source": [
    "# #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "045a0dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\srnadimp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -treamlit (c:\\users\\srnadimp\\anaconda3\\lib\\site-packages)\n",
      "ERROR: Ignored the following versions that require a different python version: 0.0.13 Requires-Python >=3.10; 0.0.17 Requires-Python >=3.10; 0.0.18 Requires-Python >=3.10; 0.0.19 Requires-Python >=3.10; 0.3.0 Requires-Python >=3.10; 0.3.1 Requires-Python >=3.10; 0.3.2 Requires-Python >=3.10; 0.3.4 Requires-Python >=3.10; 0.3.5 Requires-Python >=3.10\n",
      "ERROR: Could not find a version that satisfies the requirement semantic-link (from versions: none)\n",
      "ERROR: No matching distribution found for semantic-link\n",
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "%pip install semantic-link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7737d565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-power-bi in c:\\users\\srnadimp\\anaconda3\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: msal in c:\\users\\srnadimp\\anaconda3\\lib\\site-packages (from python-power-bi) (1.25.0)\n",
      "Requirement already satisfied: requests in c:\\users\\srnadimp\\anaconda3\\lib\\site-packages (from python-power-bi) (2.28.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in c:\\users\\srnadimp\\anaconda3\\lib\\site-packages (from PyJWT[crypto]<3,>=1.0.0->msal->python-power-bi) (2.1.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\srnadimp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -treamlit (c:\\users\\srnadimp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\srnadimp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -treamlit (c:\\users\\srnadimp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: cryptography<44,>=0.6 in c:\\users\\srnadimp\\anaconda3\\lib\\site-packages (from msal->python-power-bi) (3.4.8)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\srnadimp\\anaconda3\\lib\\site-packages (from requests->python-power-bi) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\srnadimp\\anaconda3\\lib\\site-packages (from requests->python-power-bi) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\srnadimp\\anaconda3\\lib\\site-packages (from requests->python-power-bi) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\srnadimp\\anaconda3\\lib\\site-packages (from requests->python-power-bi) (2023.7.22)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\srnadimp\\anaconda3\\lib\\site-packages (from cryptography<44,>=0.6->msal->python-power-bi) (1.15.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\srnadimp\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography<44,>=0.6->msal->python-power-bi) (2.21)\n"
     ]
    }
   ],
   "source": [
    "pip install python-power-bi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2fb653f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sempy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [36]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msempy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfabric\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mfabric\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sempy'"
     ]
    }
   ],
   "source": [
    "import sempy.fabric as fabric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa43b7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b6730b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0674302",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1914453",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf9767a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef31758",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fe44b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3264a7f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ff81c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be53f84a",
   "metadata": {},
   "source": [
    "# #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "835027ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyodbc in c:\\users\\srnadimp\\anaconda3\\lib\\site-packages (4.0.32)\n",
      "Requirement already satisfied: pandas in c:\\users\\srnadimp\\anaconda3\\lib\\site-packages (1.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\srnadimp\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\srnadimp\\anaconda3\\lib\\site-packages (from pandas) (2022.7.1)\n",
      "Requirement already satisfied: numpy>=1.20.3 in c:\\users\\srnadimp\\anaconda3\\lib\\site-packages (from pandas) (1.23.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\srnadimp\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\srnadimp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -treamlit (c:\\users\\srnadimp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\srnadimp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -treamlit (c:\\users\\srnadimp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "pip install pyodbc pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97a886bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d41135e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "InterfaceError",
     "evalue": "('IM002', '[IM002] [Microsoft][ODBC Driver Manager] Data source name not found and no default driver specified (0) (SQLDriverConnect)')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInterfaceError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m conn \u001b[38;5;241m=\u001b[39m \u001b[43mpyodbc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDRIVER=\u001b[39;49m\u001b[38;5;124;43m{\u001b[39;49m\u001b[38;5;124;43mMicrosoft Access Driver (*.mdb, *.accdb)};DBQ=POC_Artificial_Intelligence_Sample.pbix\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mInterfaceError\u001b[0m: ('IM002', '[IM002] [Microsoft][ODBC Driver Manager] Data source name not found and no default driver specified (0) (SQLDriverConnect)')"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('DRIVER={Microsoft Access Driver (*.mdb, *.accdb)};DBQ=POC_Artificial_Intelligence_Sample.pbix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc2b62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25ba7f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed366b98",
   "metadata": {},
   "source": [
    "# #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ef4447c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyDaxExtract\n",
      "  Downloading PyDaxExtract-0.2.1-py3-none-any.whl (7.7 kB)\n",
      "Installing collected packages: PyDaxExtract\n",
      "Successfully installed PyDaxExtract-0.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\srnadimp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -treamlit (c:\\users\\srnadimp\\anaconda3\\lib\\site-packages)\n",
      "  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)'))': /packages/11/7e/2d0ac3141ad17caace47a66bc7b5bf66ed0df8a6de385d786ab058b95ab1/PyDaxExtract-0.2.1-py3-none-any.whl\n",
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\srnadimp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -treamlit (c:\\users\\srnadimp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "pip install PyDaxExtract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dc1187",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5019cf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ab0f77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef2b901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6cd5f74",
   "metadata": {},
   "source": [
    "# #4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28518560",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x9d in position 152: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 27>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[0;32m     26\u001b[0m pbit_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOC_Artificial_Intelligence_Sample.pbit\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 27\u001b[0m metadata \u001b[38;5;241m=\u001b[39m \u001b[43mextract_pbix_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpbit_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Print the metadata.\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(metadata)\n",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36mextract_pbix_metadata\u001b[1;34m(pbit_file_path)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"Extracts the metadata from a PBIX file.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124;03m  A dictionary containing the metadata for the PBIX file.\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(pbit_file_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m---> 14\u001b[0m   data_model_schema \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Extract the metadata from the DataModelSchema file.\u001b[39;00m\n\u001b[0;32m     17\u001b[0m metadata \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\json\\__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[1;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(fp, \u001b[38;5;241m*\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    275\u001b[0m         parse_int\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;124;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    294\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m, object_hook\u001b[38;5;241m=\u001b[39mobject_hook,\n\u001b[0;32m    295\u001b[0m         parse_float\u001b[38;5;241m=\u001b[39mparse_float, parse_int\u001b[38;5;241m=\u001b[39mparse_int,\n\u001b[0;32m    296\u001b[0m         parse_constant\u001b[38;5;241m=\u001b[39mparse_constant, object_pairs_hook\u001b[38;5;241m=\u001b[39mobject_pairs_hook, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\encodings\\cp1252.py:23\u001b[0m, in \u001b[0;36mIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcodecs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcharmap_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdecoding_table\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x9d in position 152: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def extract_pbix_metadata(pbit_file_path):\n",
    "  \"\"\"Extracts the metadata from a PBIX file.\n",
    "\n",
    "  Args:\n",
    "    pbit_file_path: The path to the PBIT file.\n",
    "\n",
    "  Returns:\n",
    "    A dictionary containing the metadata for the PBIX file.\n",
    "  \"\"\"\n",
    "\n",
    "  with open(pbit_file_path, \"r\") as f:\n",
    "    data_model_schema = json.load(f)\n",
    "\n",
    "  # Extract the metadata from the DataModelSchema file.\n",
    "  metadata = {}\n",
    "  metadata[\"tables\"] = data_model_schema[\"tables\"]\n",
    "  metadata[\"measures\"] = data_model_schema[\"measures\"]\n",
    "  metadata[\"calculated_columns\"] = data_model_schema[\"calculatedColumns\"]\n",
    "\n",
    "  return metadata\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "pbit_file_path = \"POC_Artificial_Intelligence_Sample.pbit\"\n",
    "metadata = extract_pbix_metadata(pbit_file_path)\n",
    "\n",
    "# Print the metadata.\n",
    "print(metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f7cfe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f147cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3518881",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a39dc46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd38642",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a720ad3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e91f3a99",
   "metadata": {},
   "source": [
    "# #5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "506788e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted files: ['Connections', 'DataModel', 'DiagramLayout', 'docProps', 'Metadata', 'Report', 'SecurityBindings', 'Settings', 'Version', '[Content_Types].xml']\n",
      "{\n",
      "  \"Version\": 5,\n",
      "  \"AutoCreatedRelationships\": [],\n",
      "  \"CreatedFrom\": \"Cloud\",\n",
      "  \"CreatedFromRelease\": \"2021.10\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import json\n",
    "\n",
    "def extract_metadata(pbix_file_path):\n",
    "    # Open the .pbix file as a zip file\n",
    "    with zipfile.ZipFile(pbix_file_path, 'r') as zip_ref:\n",
    "        # Extract the contents to a temporary folder\n",
    "        temp_folder = \"temp_extract\"\n",
    "        zip_ref.extractall(temp_folder)\n",
    "\n",
    "        # Print the list of files in the temporary folder\n",
    "        print(\"Extracted files:\", os.listdir(temp_folder))\n",
    "\n",
    "        # Locate and read the metadata file\n",
    "        metadata_path = f\"{temp_folder}/Metadata\"\n",
    "        with open(metadata_path, 'r', encoding='latin-1') as metadata_file:\n",
    "            # Read the content of the file\n",
    "            metadata_content = metadata_file.read()\n",
    "\n",
    "            # Remove null bytes before decoding JSON\n",
    "            cleaned_content = metadata_content.replace('\\x00', '')\n",
    "            \n",
    "            # Manually attempt to decode the JSON string\n",
    "            try:\n",
    "                metadata = json.loads(cleaned_content)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON: {e}\")\n",
    "                metadata = None\n",
    "\n",
    "    # Cleanup: Remove the temporary folder\n",
    "    # Note: Comment this out if you want to inspect the extracted files\n",
    "    import shutil\n",
    "    shutil.rmtree(temp_folder)\n",
    "\n",
    "    return metadata\n",
    "\n",
    "# Example usage\n",
    "pbix_file_path = 'POC_Artificial_Intelligence_Sample.pbix'\n",
    "metadata = extract_metadata(pbix_file_path)\n",
    "\n",
    "# Print the extracted metadata\n",
    "if metadata is not None:\n",
    "    print(json.dumps(metadata, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c784e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3427a47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77f8de8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c618c99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c65e11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c308e69",
   "metadata": {},
   "source": [
    "# #6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c8ad3d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder C:/Users/SRNADIMP/OneDrive - Capgemini/New Laptop/OneDrive - Capgemini/Desktop/BI_Report_Template_Matching//temp_POC_Artificial_Intelligence_Sample not present\n",
      "<bound method NDFrame.head of                   Page             Visual ID                 Table  \\\n",
      "0      Key Influencers  01af2f16cdd3b0443588         Opportunities   \n",
      "1      Key Influencers  01af2f16cdd3b0443588              Products   \n",
      "2      Key Influencers  ec80685720004c638d61         Opportunities   \n",
      "3      Key Influencers  ec80685720004c638d61                Owners   \n",
      "4      Key Influencers  ec80685720004c638d61         Opportunities   \n",
      "5      Key Influencers  ec80685720004c638d61              Products   \n",
      "6      Key Influencers  ec80685720004c638d61         Opportunities   \n",
      "7      Key Influencers  ec80685720004c638d61                Owners   \n",
      "8      Key Influencers  ec80685720004c638d61              Accounts   \n",
      "9      Key Influencers  ec80685720004c638d61         Opportunities   \n",
      "10     Key Influencers  ec80685720004c638d61         Opportunities   \n",
      "11     Key Influencers  ec80685720004c638d61              Products   \n",
      "12     Key Influencers  dffa0f419ae872471ebc         Opportunities   \n",
      "13     Key Influencers  dffa0f419ae872471ebc              Products   \n",
      "14  Decomposition Tree  143a9f40e6397414f4d5             Campaigns   \n",
      "15  Decomposition Tree  143a9f40e6397414f4d5         Opportunities   \n",
      "16  Decomposition Tree  24a67f1afa332056d39b              Accounts   \n",
      "17  Decomposition Tree  24a67f1afa332056d39b         Opportunities   \n",
      "18  Decomposition Tree  954d6f9432c76cbb2ca1              Accounts   \n",
      "19  Decomposition Tree  954d6f9432c76cbb2ca1                Owners   \n",
      "20  Decomposition Tree  954d6f9432c76cbb2ca1              Products   \n",
      "21  Decomposition Tree  954d6f9432c76cbb2ca1              Accounts   \n",
      "22  Decomposition Tree  954d6f9432c76cbb2ca1              Accounts   \n",
      "23  Decomposition Tree  954d6f9432c76cbb2ca1              Products   \n",
      "24  Decomposition Tree  954d6f9432c76cbb2ca1         Opportunities   \n",
      "25   Anomaly Detection  01af2f16cdd3b0443588         Opportunities   \n",
      "26   Anomaly Detection  01af2f16cdd3b0443588              Products   \n",
      "27   Anomaly Detection  01af2f16cdd3b0443588                Owners   \n",
      "28   Anomaly Detection  dffa0f419ae872471ebc         Opportunities   \n",
      "29   Anomaly Detection  dffa0f419ae872471ebc              Products   \n",
      "30   Anomaly Detection  fc17242bbbb17dca1d06         Opportunities   \n",
      "31   Anomaly Detection  973daaf957db1570ac87  Opportunity Calendar   \n",
      "\n",
      "                 Name         Type  \n",
      "0             Close %      Measure  \n",
      "1         Product LOB       Column  \n",
      "2              Status       Column  \n",
      "3               Owner       Column  \n",
      "4    Purchase Process       Column  \n",
      "5             Product       Column  \n",
      "6               Value  Aggregation  \n",
      "7             Manager       Column  \n",
      "8            Industry       Column  \n",
      "9       Campaign Name       Column  \n",
      "10           Discount  Aggregation  \n",
      "11        Product LOB       Column  \n",
      "12        Revenue Won      Measure  \n",
      "13            Product       Column  \n",
      "14               Type       Column  \n",
      "15              Value  Aggregation  \n",
      "16             Region       Column  \n",
      "17  Opportunity Count      Measure  \n",
      "18           Industry       Column  \n",
      "19              Owner       Column  \n",
      "20            Product       Column  \n",
      "21          Territory       Column  \n",
      "22             Region       Column  \n",
      "23        Product LOB       Column  \n",
      "24              Value  Aggregation  \n",
      "25        Revenue Won      Measure  \n",
      "26   Product category       Column  \n",
      "27            Manager       Column  \n",
      "28        Revenue Won      Measure  \n",
      "29            Product       Column  \n",
      "30        Revenue Won      Measure  \n",
      "31               Date       Column  >\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from zipfile import ZipFile\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "class ReportExtractor():\n",
    "\n",
    "    def __init__(self, path, name):\n",
    "        self.path = path\n",
    "        self.name = name\n",
    "        self.result = []\n",
    "\n",
    "    def extract(self):\n",
    "        pathFolder = f'{self.path}/temp_{self.name[:-5]}'\n",
    "        try: shutil.rmtree(pathFolder)\n",
    "        except:\n",
    "            print(f'folder {pathFolder} not present')\n",
    "        f = ZipFile(f'{self.path}/{self.name}', 'r')\n",
    "        f.extractall(pathFolder)\n",
    "        report_layout = json.loads(\n",
    "            open(f'{pathFolder}/Report/Layout', 'r', encoding='utf-16 le').read()\n",
    "        )\n",
    "\n",
    "        f.close()\n",
    "        fields = []\n",
    "        for s in report_layout['sections']: \n",
    "            for vc in s['visualContainers']:       \n",
    "                try:\n",
    "                    query_dict = json.loads(vc['config'])\n",
    "                    for command in query_dict['singleVisual']['prototypeQuery']['Select']:\n",
    "\n",
    "                        if 'Measure' in command.keys():\n",
    "                            #- MEASURES\n",
    "                            name = command['Name'].split('.')[1]\n",
    "                            table = command['Name'].split('.')[0]\n",
    "                            fields.append([s['displayName'], query_dict['name'], table, name, 'Measure'])\n",
    "\n",
    "                        elif 'Column' in command.keys():\n",
    "                            # COLUMNS\n",
    "                            name = command['Name'].split('.')[1]\n",
    "                            table = command['Name'].split('.')[0]\n",
    "                            fields.append([s['displayName'], query_dict['name'], table, name, 'Column'])\n",
    "\n",
    "                        elif 'Aggregation' in command.keys():\n",
    "                            # AGGREGATIONS\n",
    "                            if ( ( '(' in command['Name'] ) & ( ')' in command['Name'] ) ): \n",
    "                                txt_extraction = command['Name'][command['Name'].find('(') + 1: command['Name'].find(')') ]\n",
    "                            name  = txt_extraction.split('.')[1]\n",
    "                            table = txt_extraction.split('.')[0]\n",
    "                            fields.append([s['displayName'], query_dict['name'], table, name, 'Aggregation'])\n",
    "\n",
    "                except: \n",
    "                    pass\n",
    "        self.result =  fields\n",
    "        shutil.rmtree(pathFolder)\n",
    "        \n",
    "        \n",
    "re = ReportExtractor(\"C:/Users/SRNADIMP/OneDrive - Capgemini/New Laptop/OneDrive - Capgemini/Desktop/BI_Report_Template_Matching/\", \"POC_Artificial_Intelligence_Sample.pbix\")\n",
    "re.extract()\n",
    "\n",
    "df = pd.DataFrame(re.result, columns=['Page', 'Visual ID', 'Table', 'Name', 'Type'])\n",
    "print(df.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3098ada8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2270ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661c6757",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62749b42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4e6ca0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65efcf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da51f61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c937ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a943c9a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d5967a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4947e570",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc70742a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1689de92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1f8ea426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1) Chat Bot\\n\\n    a. Extract the tables and fields associated with the reports (Meta data)\\n    b. Extract the visual header and x,y axis\\n'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"1) Chat Bot\n",
    "\n",
    "    a. Extract the tables and fields associated with the reports (Meta data)\n",
    "    b. Extract the visual header and x,y axis\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cbdd94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2370caa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
